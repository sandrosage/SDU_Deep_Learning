{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 100)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 100, 512)          5120000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                69760     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,200,257\n",
      "Trainable params: 5,200,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import Input, Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Embedding, LSTM, Dropout, Flatten\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import visualkeras\n",
    "\n",
    "input = Input(shape=(100,), dtype='int32', name='input')\n",
    "x = Embedding(\n",
    "    output_dim=512, input_dim=10000, input_length=100)(input)\n",
    "x = LSTM(32)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "output = Dense(1, activation='sigmoid', name='output')(x)\n",
    "model = Model(inputs=[input], outputs=[output])\n",
    "dot_img_file = 'model_1.png'\n",
    "plot_model(model, to_file=dot_img_file, show_shapes=True)\n",
    "model.summary()\n",
    "#visualkeras.layered_view(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=318x150>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Concatenate\n",
    "\n",
    "input_layer = Input(shape=(28,28,1), name='input_layer')\n",
    "conv2d_0 = Conv2D(32, kernel_size=(1, 1), activation=\"relu\", padding=\"same\")(input_layer)\n",
    "conv2d_1 = Conv2D(32, kernel_size=(1, 1), activation=\"relu\", padding=\"same\")(input_layer)\n",
    "conv2d_2 = Conv2D(32, kernel_size=(1, 1), activation=\"relu\", padding=\"same\")(input_layer)\n",
    "maxpool = MaxPooling2D(pool_size=(3, 3), strides=(1,1), padding=\"same\")(input_layer)\n",
    "conv2d_2layer_0 = Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(conv2d_1)\n",
    "conv2d_2layer_1 = Conv2D(32, kernel_size=(5, 5), activation=\"relu\", padding=\"same\")(conv2d_2)\n",
    "conv2d_2layer_2 = Conv2D(32, kernel_size=(1, 1), activation=\"relu\", padding=\"same\")(maxpool)\n",
    "concatenated = Concatenate()([conv2d_0, conv2d_2layer_0, conv2d_2layer_1, conv2d_2layer_2])\n",
    "model = Model(input_layer, concatenated)\n",
    "\n",
    "dot_img_file = 'model_2.png'\n",
    "plot_model(model, to_file=dot_img_file, show_shapes=True)\n",
    "#model.summary()\n",
    "visualkeras.layered_view(model) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "max_len =500\n",
    "batch_size =128\n",
    "NUM_WORDS =10000\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=NUM_WORDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "       ...,\n",
       "       list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 2, 325, 725, 134, 2, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 2, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 2, 7750, 5, 4241, 18, 4, 8497, 2, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 2, 4, 3586, 2]),\n",
       "       list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 9685, 6139, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 8778, 2, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   19,  178,   32],\n",
       "       [   0,    0,    0, ...,   16,  145,   95],\n",
       "       [   0,    0,    0, ...,    7,  129,  113],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    4, 3586,    2],\n",
       "       [   0,    0,    0, ...,   12,    9,   23],\n",
       "       [   0,    0,    0, ...,  204,  131,    9]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pad_sequences(train_data, maxlen=max_len)\n",
    "test_data  = pad_sequences(test_data, maxlen=max_len)\n",
    "print(train_data.shape)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 500, 128)          1280000   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 60)                45360     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,325,421\n",
      "Trainable params: 1,325,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=NUM_WORDS, output_dim=128, input_length=(train_data.shape[1])),\n",
    "    LSTM(units=60, activation=\"tanh\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "196/196 [==============================] - 158s 795ms/step - loss: 0.4076 - acc: 0.8093 - val_loss: 0.3150 - val_acc: 0.8684\n",
      "Epoch 2/5\n",
      "196/196 [==============================] - 146s 744ms/step - loss: 0.2570 - acc: 0.9021 - val_loss: 0.3171 - val_acc: 0.8703\n",
      "Epoch 3/5\n",
      "196/196 [==============================] - 140s 715ms/step - loss: 0.1829 - acc: 0.9334 - val_loss: 0.3114 - val_acc: 0.8741\n",
      "Epoch 4/5\n",
      "196/196 [==============================] - 140s 714ms/step - loss: 0.1497 - acc: 0.9448 - val_loss: 0.4117 - val_acc: 0.8674\n",
      "Epoch 5/5\n",
      "196/196 [==============================] - 138s 707ms/step - loss: 0.1023 - acc: 0.9655 - val_loss: 0.4032 - val_acc: 0.8690\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, train_labels, epochs=5, batch_size=batch_size, validation_data=(test_data, test_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "584da16cd62a9f533c0ac40541222fd213977bd98b4b3d472b8442495038f20f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
